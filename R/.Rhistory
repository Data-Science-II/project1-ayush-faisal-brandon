plot(absentFit2)
ystar = sqrt(absent$ABSRATE)
absentFit2 = lm(ystar~QTR1DUM+QTR2DUM+QTR3DUM, data = absent)
summary(absentFit2)
par(mfrow = c(2,2))
plot(absentFit2)
tvshare = read.csv("../../data/data/TVSHARE.txt", sep = "\t")
tvshare
tvshare = read.csv("../../data/data/TVSHARE.txt", sep = "\t")
tvfit = lm(MKTSHR~ADVEXP, data = tvshare)
s
summary(tvfit)
tvshare = read.csv("../../data/data/TVSHARE.txt", sep = "\t")
tvfit = lm(MKTSHR~ADVEXP, data = tvshare)
summary(tvfit)
par(mfrow = c(2,2))
plot(tvfit)
tvfit2 = lm(asin(sqrt(MKTSHR))~ADVEXP, data = tvshare)
mkt_star = asin(sqrt(MKTSHR))
mkt_star = asin(sqrt(tvshare$MKTSHR))
tvfit2 = lm(mkt_star~ADVEXP, data = tvshare)
tvshare$MKTSHR
sqrt(tvshare$MKTSHR)
asin(sqrt(tvshare$MKTSHR))
sqrt(tvshare$MKTSHR)
asin(3.87)
mkt_star = asin(sqrt(tvshare$MKTSHR))
tvshare$MKTSHR
sqrt(tvshare$MKTSHR/100)
asin(3.87)
tvfit2 = lm(mkt_star~ADVEXP, data = tvshare)
mkt_star = asin(sqrt(tvshare$MKTSHR))
tvshare$MKTSHR/100
sqrt(tvshare$MKTSHR/100)
asin()
mkt_star = asin(sqrt(tvshare$MKTSHR))
tvshare$MKTSHR/100
sqrt(tvshare$MKTSHR/100)
asin(sqrt(tvshare$MKTSHR/100))
tvfit2 = lm(mkt_star~ADVEXP, data = tvshare)
mkt_star = asin(sqrt(tvshare$MKTSHR/100))
tvfit2 = lm(mkt_star~ADVEXP, data = tvshare)
summary(tvfit2)
par(mfrow = c(2,2))
plot(tvfit2)
head(flag)
flag = read.csv("../../data/data/FLAG.txt", sep = "\t")
head(flag)
flag = read.csv("../../data/data/FLAG.txt", sep = "\t")
head(flag)
y = flag$COST
x1 = flag$DOTEST
x2 = flag$STATUS
flagfit = lm(y~x1+x2+x1:x2)
summary(flagfit)
par(mfrow= c(2,2))
plot(flagfit)
ystar = sqrt(y)
flagfit2 = lm(ystar~x1+x2+x1:x2)
summary(flagfit2)
par(mfrow = c(2,2))
plot(flagfit2)
resids = flagfit2$residuals
par(mfrow = c(2,2))
plot(x1, resids, main = "Residuals vs. DOT Estimate", xlab = "DOT Estimate")
plot(x2, resids, main = "Residuals vs. Status", xlab = "Status")
plot(x1*x2, resids, main = "Residuals vs. DOTEst*Status")
flagfit3 = lm(y~x1+x2+x1:x2+I(x1^2)+I(x1^2):x2)
summary(flagfit3)
plot(flagfit3)
flagfit3 = lm(y~x1+x2+x1:x2+I(x1^2)+I(x1^2):x2)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
flagfit3 = lm(ystar~x1+x2+x1:x2+I(x1^2)+I(x1^2):x2)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
ystar = ln(y)
ystar = log(y)
flagfit2 = lm(ystar~x1+x2+x1:x2)
summary(flagfit2)
par(mfrow = c(2,2))
plot(flagfit2)
resids = flagfit2$residuals
par(mfrow = c(2,2))
plot(x1, resids, main = "Residuals vs. DOT Estimate", xlab = "DOT Estimate")
plot(x2, resids, main = "Residuals vs. Status", xlab = "Status")
plot(x1*x2, resids, main = "Residuals vs. DOTEst*Status")
flagfit3 = lm(ystar~x1+x2+x1:x2+I(x1^2)+I(x1^2):x2)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
under2000 = where(x1 <= 2000)
under2000 = x1.where(x1 <= 2000)
under2000 = (x1 <= 2000)
under2000
under2000 = (x1 <= 2000)
par(mfrow = c(1,2))
plot(resids[under2000], x1[under2000])
plot(resids[-under2000], x1[-under2000])
under2000 = (x1 <= 2000)
over2000 = (x1 > 2000)
par(mfrow = c(1,2))
plot(x1[under2000], resids[under2000], xlab = "DOT Estimate", ylab = "Residuals")
plot(x1[over2000], resids[over2000], xlab = "DOT Estimate")
x3 = under2000
flagfit3 = (ystar~x1 + x2 + x1:x2 + x3 + I(x1^2) + I(x1^2):x3)
summary(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x1:x2 + x3 + I(x1^2) + I(x1^2):x3)
summary(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x1:x2 + x3 + I(x1^2) + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x1:x3 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x2:x3 + x1:x3 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x2:x3 + x1:x3 + I(x1^2):x3 + I(x1^2):x3:x2)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x1:x3 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x1:x3 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
plot(x1, flagfit3$residuals)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x1:x3 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x3 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x1:x3 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2:x3 + x1:x3 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x1:x3 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x1:x3 + I(x1^2):x2 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x1:x3  + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
x3 = under2000
flagfit3 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x2 + x1:x3 + I(x1^2):x2 + I(x1^2):x3)
summary(flagfit3)
par(mfrow = c(2,2))
plot(flagfit3)
flagfit4 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x3 + I(x1^2):x3)
summary(flagfit4)
anova(flagfit3, flagfit4)
flagfit4 = lm(ystar~x1 + x2 + x3 + I(x1^2) + x1:x3 + I(x1^2):x3)
anova(flagfit3, flagfit4)
summary(flagfit4)
par(mfrow = c(2,2))
plot(flagfit4)
hours = employee$HOURS[-13]
wages = employee$WAGES[-13]
employeeFit2 = lm(hours ~ wages)
summary(employeeFit2)
par(mfrow = c(2,2))
plot(employeeFit2)
par(mfrow = c(2,2))
plot(employeeFit)
x = 0.03*5
y = 0.0001*5
z = -0.00002*5
x^2+y^2+z^2
sqrt(x^2+y^2+z^2)
pnorm(.90)
?norm
qnorm(.9)
qnorm(.9)*0.15
1.25 - qnorm(.9)*0.15
1.125 - qnorm(.9)*0.15
1.125 + qnorm(.9)*0.15
1.125 + qnorm(.95)*0.15
1.125 + qnorm(.95)*0.15
qnorm(.95)
1.125 - qnorm(.95)*0.15
pchisq(7.5, 2)
pchisq(7.5, 2)
1-pchisq(7.5, 2)
3.35^2
pnorm(6)
1-pnorm(6) * 2
1-pnorm(6)
(1-pnorm(6))*2
?apply
apply(red_train, 2, plot, red_train$quality)
library(ggplot2)
library(reshape2)
source("regression_utils.R")
red_wine = read.csv("../data/WineQuality/winequality-red.csv", sep = ";")
white_wine = read.csv("../data/WineQuality/winequality-white.csv", sep = ";")
head(red_wine)
head(white_wine)
#splitting the datasets for cross-validation
train_index = train_test_split(red_wine, 0.80)
red_train = red_wine[train_index,] #size 1279
red_test = red_wine[-train_index,] #size 320
train_index = train_test_split(white_wine, 0.80)
white_train = white_wine[train_index,] #size 3918
white_test = white_wine[-train_index,] #size 980
pwd()
pwd
wd()
wd
getwd()
setwd("D:/CS4360/project1/R/")
library(ggplot2)
library(reshape2)
source("regression_utils.R")
red_wine = read.csv("../data/WineQuality/winequality-red.csv", sep = ";")
white_wine = read.csv("../data/WineQuality/winequality-white.csv", sep = ";")
head(red_wine)
head(white_wine)
#splitting the datasets for cross-validation
train_index = train_test_split(red_wine, 0.80)
red_train = red_wine[train_index,] #size 1279
red_test = red_wine[-train_index,] #size 320
train_index = train_test_split(white_wine, 0.80)
white_train = white_wine[train_index,] #size 3918
white_test = white_wine[-train_index,] #size 980
##Exploratory Data Analysis
#correlation matrices to determine collinearity
apply(red_train, 2, plot, red_train$quality)
apply(red_train, 2, plot, red_train$quality, xlab = names(red_train)[i])
apply(red_train, 2, plot, red_train$quality, xlab = names(red_train))
apply(red_train, 2, plot, red_train$quality)
?apply
mapply(red_train, 2, plot, red_train$quality)
#reproducibility for both dataframes (red_wine, white_wine)
par(mfrow(c(4,3)))
#reproducibility for both dataframes (red_wine, white_wine)
par(mfrow = (c(4,3)))
apply(red_train, 2, plot, red_train$quality)
scatter_wine = function(wine_frame) {
par(mfrow = (c(4,3)),
mar = c(2,2,2,2))
for (i in 1:12) {
plot(wine_frame[,i], wine_frame$quality,
xlab = names(wine_frame)[i],
ylab = "quality")
} # for i
} #scatter_wine
scatter_wine(red_wine)
scatter_wine = function(wine_frame) {
par(mfrow = (c(4,3)),
mar = c(3,3,3,3))
for (i in 1:12) {
plot(wine_frame[,i], wine_frame$quality,
xlab = names(wine_frame)[i],
ylab = "quality")
} # for i
} #scatter_wine
scatter_wine(red_wine)
scatter_wine = function(wine_frame) {
par(mfrow = (c(4,3)))
for (i in 1:12) {
plot(wine_frame[,i], wine_frame$quality,
xlab = names(wine_frame)[i],
ylab = "quality")
} # for i
} #scatter_wine
(red_wine)
scatter_wine(red_wine)
scatter_wine(white_wine)
test_model = lm(quality ~ fixed.acidity + volatile.acidity +
citric.acid ,data = red_wine)
summary(test_model)
rsq_cv = function(formula, dataset, folds) {
model = (formula = formula, data = dataset)
summary(model)
} #rsq_cv
?lm
rsq_cv = function(formula, dataset, folds) {
model = lm(formula, data = dataset)
summary(model)
} #rsq_cv
rsq_cv(formula1)
formula1 = as.formula(quality ~ fixed.acidity + volatile.acidity + citric.acid +
residual.sugar + chlorides)
rsq_cv(formula1)
rsq_cv(formula1, red_wine, 0)
test_seq = seq_len(100)
test_seq
sample(test_seq)
test_seq = sample(test_seq)
test_seq[1:10]
test_seq[90:100]
test_seq[91:100]
selection = 1+((i-1)*10):i*10
for (i in 1:10) {
selection = 1+((i-1)*10):i*10
}
for (i in 1:10) {
selection = 1+((i-1)*10):i*10
print(selection)
}
lower = 1+((i-1)*10)
for (i in 1:10) {
lower = 1+((i-1)*10)
upper = i*10
print(c(lower, upper))
}
for (i in 1:10) {
lower = 1+((i-1)*10)
upper = i*10
test_seq[lower:upper]
}
for (i in 1:10) {
lower = 1+((i-1)*10)
upper = i*10
print(test_seq[lower:upper])
}
lm(formula1, data = red_wine)
lm(formula1, data = red_wine).sse
lm(formula1, data = red_wine).coef
m = lm(formula1, data = red_wine)
predict(m)
k = 2
k +=1
k = k + 1
k
rsq_cv = function(formula, dataset, k, seed = 4360) {
set.seed(4360)
n = nrow(dataset)
partition_size = as.integer(n/k)
partition = sample(seq_len(n))
running_sse = 0
for (i in 1:k){
lower = 1+((i-1)*partition_size)
upper = i*partition_size
testing_selection = partition[lower:upper]
#divide for cross validation
training_set = dataset[-testing_selection,]
testing_set = dataset[testing_selection, ]
#run the model and predict testing set data
model = lm(formula, data = training_set)
yhat = predict(model, testing_set)
#calculate sse and add it running total
sse = sum((yhat-training_set$quality)^2)
running_sse = running_sse + sse
} # for i
sst = var(dataset$quality)*n
rsq = 1 - (running_sse/sst)
return(rsq)
} #rsq_cv
rsq_cv = function(formula, dataset, k, seed = 4360) {
set.seed(seed)
n = nrow(dataset)
partition_size = as.integer(n/k)
partition = sample(seq_len(n))
running_sse = 0
for (i in 1:k){
lower = 1+((i-1)*partition_size)
upper = i*partition_size
testing_selection = partition[lower:upper]
#divide for cross validation
training_set = dataset[-testing_selection,]
testing_set = dataset[testing_selection, ]
#run the model and predict testing set data
model = lm(formula, data = training_set)
yhat = predict(model, testing_set)
#calculate sse and add it running total
sse = sum((yhat-training_set$quality)^2)
running_sse = running_sse + sse
} # for i
sst = var(dataset$quality)*n
rsq = 1 - (running_sse/sst)
return(rsq)
} #rsq_cv
rsq_cv(formula1, red_wine, 10)
rsq_cv = function(formula, dataset, k, seed = 4360) {
set.seed(seed)
n = nrow(dataset)
partition_size = as.integer(n/k)
partition = sample(seq_len(n))
running_sse = 0
for (i in 1:k){
lower = 1+((i-1)*partition_size)
upper = i*partition_size
testing_selection = partition[lower:upper]
#divide for cross validation
training_set = dataset[-testing_selection,]
testing_set = dataset[testing_selection, ]
#run the model and predict testing set data
model = lm(formula, data = training_set)
yhat = predict(model, testing_set)
#calculate sse and add it running total
sse = sum((yhat-testing_set$quality)^2)
running_sse = running_sse + sse
} # for i
sst = var(dataset$quality)*n
rsq = 1 - (running_sse/sst)
return(rsq)
} #rsq_cv
rsq_cv(formula1, red_wine, 10)
rsq_cv = function(formula, dataset, k, response, seed = 4360) {
set.seed(seed)
n = nrow(dataset)
partition_size = as.integer(n/k)
partition = sample(seq_len(n))
running_sse = 0
for (i in 1:k){
lower = 1+((i-1)*partition_size)
upper = i*partition_size
testing_selection = partition[lower:upper]
#divide for cross validation
training_set = dataset[-testing_selection,]
testing_set = dataset[testing_selection, ]
#run the model and predict testing set data
model = lm(formula, data = training_set)
yhat = predict(model, testing_set)
#calculate sse and add it running total
sse = sum((yhat-testing_set[, response])^2)
running_sse = running_sse + sse
} # for i
sst = var(dataset[, response])*n
rsq = 1 - (running_sse/sst)
return(rsq)
} #rsq_cv
rsq_cv(formula1, red_wine, 10, "quality")
red_wine = read.csv("../data/WineQuality/winequality-red.csv", sep = ";")
white_wine = read.csv("../data/WineQuality/winequality-white.csv", sep = ";")
scatter(red_wine, "quality", col = 3, row = 4)
library(ggplot2)
library(reshape2)
source("regression_utils.R")
scatter(red_wine, "quality", col = 3, row = 4)
source("regression_utils.R")
scatter(red_wine, "quality", col = 3, row = 4)
scatter = function(frame, response, row, col) {
par(mfrow = (c(row,col)),
mar = c(3, 3, 3, 3))
num_col = ncol(frame)
for (i in 1:num_col) {
plot(frame[,i], frame[,response],
xlab = names(frame)[i],
ylab = response)
} # for i
} #scatter
scatter(red_wine, "quality", col = 3, row = 4)
scatter = function(frame, response, row, col) {
par(mfrow = (c(row,col)),
mar = c(6, 3, 3, 3))
num_col = ncol(frame)
for (i in 1:num_col) {
plot(frame[,i], frame[,response],
xlab = names(frame)[i],
ylab = response)
} # for i
} #scatter
scatter(red_wine, "quality", col = 3, row = 4)
scatter = function(frame, response, row, col) {
par(mfrow = (c(row,col)),
mar = c(4, 4, 3, 3))
num_col = ncol(frame)
for (i in 1:num_col) {
plot(frame[,i], frame[,response],
xlab = names(frame)[i],
ylab = response)
} # for i
} #scatter
scatter(red_wine, "quality", col = 3, row = 4)
lm(full_formula, red_wine)
###feature selection
#feature selection using forward selection
full_formula = as.formula(quality ~ fixed.acidity +
volatile.acidity + citric.acid +
residual.sugar + chlorides +
free.sulfur.dioxide + total.sulfur.dioxide +
density + pH + sulphates + alcohol)
lm(full_formula, red_wine)
empty_formula = as.forumla(quality~1)
empty_formula = as.formula(quality~1)
