\documentclass{article}

\usepackage{geometry}
\geometry{letterpaper, total={7in, 10in} }
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{verbatim}

\title{CSCI 4360 Data Science II \protect\\ Project I}
\author{Ayush Kumar, Brandon Amirouche, Faisal Hossain}
\date{February 24, 2021}

\begin{document} 
	
	\maketitle
	\tableofcontents
	\newpage


	\section{Introduction and Methodology}


	\subsection{Code Credits}


	\section{Auto-MPG}


	\section{Concrete Compressive Strength} 

	\subsection{The Dataset}

	The concrete compressive strength is a highly nonlinear function of age and ingredients used to determine the quality 
	of concrete. These ingredients include cement, blast furnace slag, fly ash, water, superplasticizer, coarse aggregate, 
	and fine aggregate. The Concrete Compressive Strength Data Set has 1,030 observations with a total of 9 attributes - 8 
	quantitative input variables, and 1 quantitative output variable. The data file can be found in the the data/ConcreteCompressiveStrength 
	folder, and were orignally downloaded from the UCI Machine Learning The dataset has the following variables: 
	
	\begin{enumerate}
		\item Cement (kg in a m3 mixture)
		\item Blast Furnace Slag (kg in a m3 mixture)
		\item Fly Ash (kg in a m3 mixture)
		\item Water (kg in a m3 mixture)
		\item Superplasticizer (kg in a m3 mixture)
		\item Coarse Aggregate (kg in a m3 mixture)
		\item Fine Aggregate (kg in a m3 mixture)
		\item Age (Day 1$\sim$365)
		\item Concrete (MPa) - the response variable
	\end{enumerate}
	
	\subsection{Exploratory Data Analysis}
	During Exploratory Data Analysis (EDA), the value of y is plotted against each feature/column x:j of data matrix X 
	in order to understand the data and gain insights from the data. A correlation matrix is used to check the correlations 
	between the input features.
	
	\textbf{ Concrete Compressive Strength Correlation Matrix (Plotted with R)}
	
	\includegraphics[scale=0.7]{../plots/ConcreteCompressiveStrength/concrete-corr.png}

	From the Concrete Compressive Strength Correlation Matrix (Figure 1) we can visually check for features that have 
	fairly strong correlations with the response variable and each other. We can observe a high positive correlation 
	between Cement and the response variable, Concrete Compressive Strength. Age and Super Plasticizer are two other 
	factors influencing Concrete Compressive Strength. Additionally by observing between features, we can see a strong 
	negative correlation between Super Plasticizer and Water; and a strong correlation between Super Plasticizer and Fly 
	Ash, Fine Aggregate. Eliminating redundant variables or irrelevant variables may limit collinearity, reduce loss in 
	our accuracy, and increase efficiency in our model.	

	\newpage 

	\textbf{ Concrete Compressive Strength Scatter Plots (Plotted with R)}
	
	\includegraphics[scale=0.55]{../plots/ConcreteCompressiveStrength/concrete-scatter.png}
	
	Using the scatters plots of Concrete Compressive (Figure 2) we can observe the relationships and identify patterns 
	between features. From the scatter plots, we observe that Concrete Compressive Strength increases as the amount of 
	cement increases, water decreases, and age increases.

	\subsection{Variable Screening and Selection}
	
	\textbf{Variable Selection for Concrete Compressive Strength} 


	\section{Crime}


	\section{Wine Quality}
	
	The wine quality data is actually two datasets, one for red wine and the other for white 
	wine. Both of them have the same 11 features, but there may be differences in the features 
	that matter, as well as the overall results of regression. A dummy variable could be created 
	to meld the datasets into one overall set, but if there are substantial differences between 
	the two it may substantially add to model complexity. The dataset has the following variables: 
	
	\begin{enumerate}
		\item fixed.acidity 
		\item volatile.acidity 
		\item citric.acid 
		\item residual.sugar 
		\item chlorides 
		\item free.sulfur.dioxide 
		\item total.sulfur.dioxide 
		\item density
		\item pH
		\item sulfates 
		\item alcohol 
		\item quality (the response variable)
	\end{enumerate}

	The red wine dataset has 1,599 observations, and the white wine dataset has 4,898 observations. 
	The two files can be found in the data/WineQuality folder, and were orignally downloaded from 
	the UCI Machine Learning Repository. [insert link here]

	\subsection{Exploratory Data Analysis}
	
	The first step in EDA was to checkout the collinearity of features, and how well they correlate 
	with our response variables. 
	
	
	\textbf{ Red Wine Correlation Matrix (Plotted with R)}
	
	\includegraphics[scale=0.5]{../plots/Wine/red_wine_Rcormat.png}

	From the Red Wine Correlation Matrix (Figure 1) we can see that there are a few variables that have fairly strong 
	correlations with each other. The citric acid content and the fixed acidity seem to be highly correlated 
	with each other, and this pattern holds true for many of the features that depend on acidity. We can see 
	that pH is highly correlated with fixed acidity and citric acid as well. This will be important to consider 
	as it may create a problem in our regression. Based on the results of our variable screening methods, we may
	consider dropping one or more these variables, or using them as an instrumental variable to reduce the 
	endogeneity issue with this dataset. Another highly correlated issue may be density and fixed acidity, as well 
	as free.sulfur.dioxide and total sulfur dioxide. It may be worth our time to standardize some of these 
	variables to limit collinearity, and this will be considered during variable selection. 
	
	
	\newpage 
	
	\textbf{Red Wine Scatter Plots (R)}
	
	\includegraphics[scale=0.7]{../plots/Wine/red_wine_Rscatter.png}
	\newline
	
	Quality seems to be a multi-categorical variable, based on this information maybe regression is not the best
	way to predict on this dataset, but it may give a great deal of information regarding feature selection. Some
	features exhibit very peculiar behavior of having similar characteristics for both low and high quality wines, but
	not for middle quality wines. This can be illustrated when we take a look at total sulfur dioxide, chlorides, and 
	residual sugar. This pattern may mislead us during variable selection, so it may be a good idea to add in 
	quadratic terms for these variables to account for their curving behavior. If these variables fail to be selected 
	initially then I will rerun variable selection methods taking into account their quadratic terms. There may 
	be other transformations needed, but we can determine those after variable selection bases on partial residual 
	plots. 
	
	\newpage
	. 

	\subsection{Multiple Linear Regression}
	

	\textbf{Variable Selection for Red Wine} 
	
	
		Output has been modified for space. Run code for full output. 
	\verbatiminput{../R/output/wine/red_forward_selectionR.txt}

	One of the variables that was omitted here was residual sugar, one of the variables that exhibited very strong 
	quadratic behavior. I will be rerunning forward selection while including the quadratic term for residual sugar 
	and it will be included for all of the following variable selection methods as well. This is the final call when 
	I include the quadratic term in the forward step. 
	
	\begin{verbatim}
			Call:
				lm(formula = quality ~ alcohol + volatile.acidity + sulphates + 
				total.sulfur.dioxide + chlorides + pH + free.sulfur.dioxide, 
				data = red_wine)
	\end{verbatim}
	
	As can be seen even the inclusion of the quadratic term did not change the results of the forward selection. Below
	are listed the final conclusions of backwards elimination and step wise regression. 
	
	\textbf{Backward Elimination}
	\begin{verbatim}
			Call:
				lm(formula = quality ~ volatile.acidity + chlorides + free.sulfur.dioxide + 
				total.sulfur.dioxide + pH + sulphates + alcohol, data = red_wine)
	\end{verbatim}
	
	\textbf{Step Regression} 
	\begin{verbatim}
			Call:
				lm(formula = quality ~ alcohol + volatile.acidity + sulphates + 
				total.sulfur.dioxide + chlorides + pH + free.sulfur.dioxide, 
				data = red_wine)
	\end{verbatim}
	
	
	While the methods may be different every single one of our variable screening methods chose the same seven variables 
	to include: alcohol, volatile.acidity, sulphates, total.sulfur.dioxide, chlorides, pH, and free.sulfur.dioxide. These 
	are the variables that will be included in all our models for red wine moving forward. 
	
	\includegraphics[scale=.55]{../plots/Wine/qof_plotR.png}
	
	\begin{figure}
	\begin{center}


		\caption \newline Graphs for Quality of Fit (Backward, Forward, Stepwise)
		
		
		\includegraphics[scale=0.25]{../plots/Wine/Scala/MultipleLinearRegressionForwardSel.png}
		\includegraphics[scale=0.25]{../plots/Wine/Scala/MultipleLinearRegressionBackElim.png}
		
		
		\includegraphics[scale=0.25]{../plots/Wine/Scala/MultipleLinearRegressionStepReg.png}
	\end{center}
	\end{figure}

	
	Here we can see that as we increase the number of variables, we see diminishing marginal improvement in quality of 
	fit. For measures that penalize model complexity such as $R^2$ and AIC we can even see a light bend towards 
	the quality of fit worsening as model complexity increases. The diminishing returns can in part be explained by 
	variables that have weak correlation 
	
	
	
	\subsection{Quadratic Regression} 
	
	All linear and quadratic terms were included for forward selection, backward elimination, 
	and step wise regression in both ScalaTion and R. The optimal models are shown here 
	in the table alongside the 4 quality of fit measures. $R^2$, $R^2_{cv}$, $\bar R^2$, AIC. 
			
	\begin{figure}
	\begin{center}


		\caption \newline Graphs for Quality for Fit (Wine Quadratic)
		
		\includegraphics[scale=0.25]{../plots/Wine/Scala/QuadraticRegressionForwardSel.png}
		\includegraphics[scale=0.25]{../plots/Wine/Scala/QuadraticRegressionBackElim.png}
		
		
		\includegraphics[scale=0.25]{../plots/Wine/Scala/QuadraticRegressionStepReg.png}
	\end{center}
	\end{figure}

	Here we can see that as we begin to increase the complexity of the model past a certain 
	point that it begins to over-fit which results in the $R^2$ and $adj-R^2$ to continue 
	increasing, but when we cross=validate the $R^2$ is substantially lower. This is a 
	problem. 

	\subsection{Quadratic Regression with Cross Terms} 
	\begin{figure}
	\begin{center}
		
		\caption \newline Graphs for Quality for Fit (Wine Quadratic-Cross)
		
		\includegraphics[scale=0.25]{../plots/Wine/Scala/QuadraticCrossRegressionForwardSel.png}
		\includegraphics[scale=0.25]{../plots/Wine/Scala/QuadraticCrossRegressionBackElim.png}
		
		
		\includegraphics[scale=0.25]{../plots/Wine/Scala/QuadraticCrossRegressionStepReg.png}
	\end{center}
	\end{figure}

	The effect of the drop in $R^2_{cv}$ and the non-cross validated measures show 
	that increasing the number of variables results in models that are severely over fit. 
	By using the Stepwise regression we can see that as soon as the non-cross validated 
	measures start to decline we should stop adding more variables to maintain a model useful 
	outside of the training dataset. 
	
	\subsection{Cubic Regression} 
	\subsection{Cubic Regression with Cross Terms} 
	
	
	\section{Seoul Bike Rentals}
	\section{Air Quality}
	
	
\end{document}
